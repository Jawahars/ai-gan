{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project: A Trilogy of GANs on MNIST**\n",
    "\n",
    "This notebook implements and compares three foundational types of Generative Adversarial Networks.\n",
    "\n",
    "*   **Part 1: Vanilla GAN**: The original GAN architecture using Binary Cross-Entropy loss.\n",
    "*   **Part 2: Wasserstein GAN (WGAN)**: An improved architecture using Wasserstein loss and weight clipping to enhance training stability.\n",
    "*   **Part 3: Spectral Normalization GAN (SNGAN)**: A modern approach using Spectral Normalization and Hinge Loss for even more stable and high-quality training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Common Setup: Imports and Reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set a Global Random Seed for Reproducibility ---\n",
    "# This ensures that weight initializations, data shuffling, and noise vectors are the same for each run,\n",
    "# allowing for a fair comparison between the models.\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # For multi-GPU setups\n",
    "    # The following two lines are for full reproducibility on GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "image_size = 28 * 28\n",
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "\n",
    "# Image processing and dataset loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1: Vanilla GAN with BCE Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid() # Outputs a probability\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, image_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_vanilla = 0.0002\n",
    "\n",
    "discriminator_vanilla = Discriminator().to(device)\n",
    "generator_vanilla = Generator().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer_vanilla = optim.Adam(discriminator_vanilla.parameters(), lr=learning_rate_vanilla)\n",
    "g_optimizer_vanilla = optim.Adam(generator_vanilla.parameters(), lr=learning_rate_vanilla)\n",
    "d_losses_vanilla, g_losses_vanilla = [], []\n",
    "\n",
    "os.makedirs('vanilla_gan_samples', exist_ok=True)\n",
    "\n",
    "print(\"Starting Vanilla GAN Training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_d_loss, epoch_g_loss = 0.0, 0.0\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        real_labels = torch.ones(images.size(0), 1).to(device)\n",
    "        fake_labels = torch.zeros(images.size(0), 1).to(device)\n",
    "        images = images.reshape(-1, image_size).to(device)\n",
    "\n",
    "        d_optimizer_vanilla.zero_grad()\n",
    "        d_real_outputs = discriminator_vanilla(images)\n",
    "        d_loss_real = criterion(d_real_outputs, real_labels)\n",
    "        z = torch.randn(images.size(0), latent_dim).to(device)\n",
    "        fake_images = generator_vanilla(z)\n",
    "        d_fake_outputs = discriminator_vanilla(fake_images.detach())\n",
    "        d_loss_fake = criterion(d_fake_outputs, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        d_optimizer_vanilla.step()\n",
    "\n",
    "        g_optimizer_vanilla.zero_grad()\n",
    "        g_outputs = discriminator_vanilla(fake_images)\n",
    "        g_loss = criterion(g_outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        g_optimizer_vanilla.step()\n",
    "        \n",
    "        epoch_d_loss += d_loss.item()\n",
    "        epoch_g_loss += g_loss.item()\n",
    "\n",
    "    avg_d_loss = epoch_d_loss / len(train_loader)\n",
    "    avg_g_loss = epoch_g_loss / len(train_loader)\n",
    "    d_losses_vanilla.append(avg_d_loss)\n",
    "    g_losses_vanilla.append(avg_g_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], D Loss: {avg_d_loss:.4f}, G Loss: {avg_g_loss:.4f}')\n",
    "\n",
    "print(\"Vanilla GAN Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2: Wasserstein GAN (WGAN) with Weight Clipping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1) # No Sigmoid for WGAN critic\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_wgan = 0.00005\n",
    "critic_iterations = 5\n",
    "clip_value = 0.01\n",
    "\n",
    "critic_wgan = Critic().to(device)\n",
    "generator_wgan = Generator().to(device)\n",
    "d_optimizer_wgan = optim.RMSprop(critic_wgan.parameters(), lr=learning_rate_wgan)\n",
    "g_optimizer_wgan = optim.RMSprop(generator_wgan.parameters(), lr=learning_rate_wgan)\n",
    "d_losses_wgan, g_losses_wgan = [], []\n",
    "\n",
    "os.makedirs('wgan_samples', exist_ok=True)\n",
    "\n",
    "print(\"Starting WGAN Training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_d_loss, epoch_g_loss = 0.0, 0.0\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, image_size).to(device)\n",
    "\n",
    "        for _ in range(critic_iterations):\n",
    "            d_optimizer_wgan.zero_grad()\n",
    "            z = torch.randn(images.size(0), latent_dim).to(device)\n",
    "            fake_images = generator_wgan(z).detach()\n",
    "            real_output = critic_wgan(images)\n",
    "            fake_output = critic_wgan(fake_images)\n",
    "            d_loss = -(torch.mean(real_output) - torch.mean(fake_output))\n",
    "            d_loss.backward()\n",
    "            d_optimizer_wgan.step()\n",
    "            for p in critic_wgan.parameters():\n",
    "                p.data.clamp_(-clip_value, clip_value)\n",
    "        \n",
    "        epoch_d_loss += d_loss.item()\n",
    "\n",
    "        g_optimizer_wgan.zero_grad()\n",
    "        z = torch.randn(images.size(0), latent_dim).to(device)\n",
    "        fake_images_for_g = generator_wgan(z)\n",
    "        g_loss = -torch.mean(critic_wgan(fake_images_for_g))\n",
    "        g_loss.backward()\n",
    "        g_optimizer_wgan.step()\n",
    "\n",
    "        epoch_g_loss += g_loss.item()\n",
    "\n",
    "    avg_d_loss = epoch_d_loss / len(train_loader)\n",
    "    avg_g_loss = epoch_g_loss / len(train_loader)\n",
    "    d_losses_wgan.append(avg_d_loss)\n",
    "    g_losses_wgan.append(avg_g_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Critic Loss: {avg_d_loss:.4f}, Generator Loss: {avg_g_loss:.4f}')\n",
    "\n",
    "print(\"WGAN Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3: Spectral Normalization GAN (SNGAN) with Hinge Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "class SNGAN_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNGAN_Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            spectral_norm(nn.Linear(image_size, 512)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            spectral_norm(nn.Linear(512, 256)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            spectral_norm(nn.Linear(256, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_sngan = 0.0002\n",
    "\n",
    "discriminator_sngan = SNGAN_Discriminator().to(device)\n",
    "generator_sngan = Generator().to(device)\n",
    "d_optimizer_sngan = optim.Adam(discriminator_sngan.parameters(), lr=learning_rate_sngan, betas=(0.5, 0.999))\n",
    "g_optimizer_sngan = optim.Adam(generator_sngan.parameters(), lr=learning_rate_sngan, betas=(0.5, 0.999))\n",
    "d_losses_sngan, g_losses_sngan = [], []\n",
    "\n",
    "os.makedirs('sngan_samples', exist_ok=True)\n",
    "\n",
    "print(\"Starting SNGAN Training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_d_loss, epoch_g_loss = 0.0, 0.0\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, image_size).to(device)\n",
    "\n",
    "        d_optimizer_sngan.zero_grad()\n",
    "        real_output = discriminator_sngan(images)\n",
    "        d_loss_real = torch.mean(nn.ReLU()(1.0 - real_output))\n",
    "        z = torch.randn(images.size(0), latent_dim).to(device)\n",
    "        fake_images = generator_sngan(z).detach()\n",
    "        fake_output = discriminator_sngan(fake_images)\n",
    "        d_loss_fake = torch.mean(nn.ReLU()(1.0 + fake_output))\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        d_optimizer_sngan.step()\n",
    "        epoch_d_loss += d_loss.item()\n",
    "\n",
    "        g_optimizer_sngan.zero_grad()\n",
    "        z = torch.randn(images.size(0), latent_dim).to(device)\n",
    "        fake_images_for_g = generator_sngan(z)\n",
    "        g_output = discriminator_sngan(fake_images_for_g)\n",
    "        g_loss = -torch.mean(g_output)\n",
    "        g_loss.backward()\n",
    "        g_optimizer_sngan.step()\n",
    "        epoch_g_loss += g_loss.item()\n",
    "\n",
    "    avg_d_loss = epoch_d_loss / len(train_loader)\n",
    "    avg_g_loss = epoch_g_loss / len(train_loader)\n",
    "    d_losses_sngan.append(avg_d_loss)\n",
    "    g_losses_sngan.append(avg_g_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Discriminator Loss: {avg_d_loss:.4f}, Generator Loss: {avg_g_loss:.4f}')\n",
    "\n",
    "print(\"SNGAN Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 4: Evaluation and Comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loss Curve Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Vanilla GAN Loss\")\n",
    "plt.plot(d_losses_vanilla, label=\"D Loss\")\n",
    "plt.plot(g_losses_vanilla, label=\"G Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"WGAN Loss\")\n",
    "plt.plot(d_losses_wgan, label=\"Critic Loss\")\n",
    "plt.plot(g_losses_wgan, label=\"G Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"SNGAN Loss\")\n",
    "plt.plot(d_losses_sngan, label=\"D Loss\")\n",
    "plt.plot(g_losses_sngan, label=\"G Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_loss_curves.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Final Generated Samples (Fair Comparison)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create ONE fixed latent vector for the final comparison ---\n",
    "# This ensures we are comparing what each generator produces from the exact same input noise.\n",
    "fixed_z = torch.randn(64, latent_dim).to(device)\n",
    "\n",
    "def show_final_samples(generator, title, filename, z_vector):\n",
    "    \"\"\"Generates and displays samples from a generator using a fixed noise vector.\"\"\"\n",
    "    generator.eval() # Set generator to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Use the fixed z_vector passed as an argument\n",
    "        final_images = generator(z_vector).view(-1, 1, 28, 28)\n",
    "        save_image(final_images, filename, normalize=True)\n",
    "        \n",
    "        grid = torchvision.utils.make_grid(final_images, nrow=8, normalize=True)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(grid.permute(1, 2, 0).cpu())\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# --- Generate and display samples using the SAME fixed_z for all models ---\n",
    "print(\"Displaying final samples. Each model received the exact same input noise.\")\n",
    "\n",
    "show_final_samples(generator_vanilla, 'Final Vanilla GAN Samples', 'final_vanilla_gan_samples.png', fixed_z)\n",
    "show_final_samples(generator_wgan, 'Final WGAN Samples', 'final_wgan_samples.png', fixed_z)\n",
    "show_final_samples(generator_sngan, 'Final SNGAN Samples', 'final_sngan_samples.png', fixed_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **IS and FID Score Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-fidelity\n",
    "\n",
    "def generate_for_evaluation(generator, eval_dir, num_images=10000):\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "    eval_batch_size = 100\n",
    "    print(f\"Generating {num_images} images into '{eval_dir}'...\")\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_images, eval_batch_size):\n",
    "            z = torch.randn(eval_batch_size, latent_dim).to(device)\n",
    "            generated_images = generator(z).view(-1, 1, 28, 28)\n",
    "            for j in range(generated_images.size(0)):\n",
    "                save_image(generated_images[j, :, :, :], os.path.join(eval_dir, f'img_{i+j}.png'), normalize=True)\n",
    "    print(f\"Finished generating images for {eval_dir}.\")\n",
    "\n",
    "generate_for_evaluation(generator_vanilla, 'vanilla_eval_images')\n",
    "generate_for_evaluation(generator_wgan, 'wgan_eval_images')\n",
    "generate_for_evaluation(generator_sngan, 'sngan_eval_images')\n",
    "\n",
    "real_images_dir = 'real_mnist_images'\n",
    "if not os.path.exists(real_images_dir):\n",
    "    os.makedirs(real_images_dir, exist_ok=True)\n",
    "    print(f\"Saving real MNIST images to '{real_images_dir}'...\")\n",
    "    real_train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    img_num = 0\n",
    "    for i, (images, _) in enumerate(real_train_loader):\n",
    "        for j in range(images.size(0)):\n",
    "            save_image(images[j, :, :, :], os.path.join(real_images_dir, f'real_img_{num_images}.png'), normalize=True)\n",
    "            img_num += 1\n",
    "    print(\"Finished saving real images.\")\n",
    "else:\n",
    "    print(f\"Real images directory '{real_images_dir}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run Evaluation Commands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Calculating metrics for Vanilla GAN ---\")\n",
    "!python -m torch_fidelity.fidelity --gpu 0 --fid --isc --input1 /content/vanilla_eval_images --input2 /content/real_mnist_images\n",
    "\n",
    "print(\"\\n--- Calculating metrics for WGAN ---\")\n",
    "!python -m torch_fidelity.fidelity --gpu 0 --fid --isc --input1 /content/wgan_eval_images --input2 /content/real_mnist_images\n",
    "\n",
    "print(\"\\n--- Calculating metrics for SNGAN ---\")\n",
    "!python -m torch_fidelity.fidelity --gpu 0 --fid --isc --input1 /content/sngan_eval_images --input2 /content/real_mnist_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Final Comparison**\n",
    "After running the notebook and calculating the metrics, this table is filled in with the final scores to compare the performance of the three models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric | Vanilla GAN (BCE Loss) | WGAN (Wasserstein Loss) | SNGAN (Hinge Loss) | Analysis |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Stabilization Method** | None (uses Sigmoid) | Weight Clipping | Spectral Normalization | SNGAN is theoretically the most robust method, but WGAN's weight clipping proved highly effective in this experiment. |\n",
    "| **Training Stability** | Loss is volatile and does not correlate well with image quality. | Loss is more stable and meaningful, providing a useful proxy for convergence. | Also provides stable and meaningful loss curves. | Both WGAN and SNGAN offer a significant improvement in training stability over the Vanilla GAN. |\n",
    "| **Visual Quality** | Suffers from significant noise and mode collapse is a risk. | Produces much cleaner images with fewer artifacts, demonstrating better convergence. | Shows good potential but was likely limited by hyperparameter tuning in this run. | The WGAN produced the most visually appealing and realistic samples in this specific experiment. |\n",
    "| **Inception Score (IS)** | **2.10** | **2.09** | **1.86** | The Vanilla GAN and WGAN produced similarly diverse and recognizable images. The lower SNGAN score suggests it had not converged to its optimal state. |\n",
    "| **Fréchet Distance (FID)** | **143.59** | **91.09** | **108.99** | **WGAN is the clear winner.** Its FID score shows a massive improvement in realism over the Vanilla GAN. The SNGAN also improved upon the Vanilla GAN but was outperformed by the well-tuned WGAN in this test. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Insights and Observations\n",
    "\n",
    "This series of experiments provides a clear progression in GAN technology and highlights key trade-offs in model design and training. By holding the generator architecture constant and only changing the discriminator and loss function, we can draw direct conclusions about the effectiveness of each method.\n",
    "\n",
    "### Training Stability and Convergence Speed\n",
    "\n",
    "*   **Vanilla GAN**: The loss curves confirm the instability of the original GAN formulation. The losses for the generator and discriminator oscillate wildly, and their values are not a reliable indicator of image quality. A lower loss does not necessarily mean better images.\n",
    "*   **WGAN**: The training process is visibly more stable. The critic's loss provides a much more meaningful metric that correlates with image quality; as the generator improves, the critic's loss (approximating the Earth Mover's distance) tends to decrease. While training is slower *per epoch* due to the multiple critic updates, the *convergence to high-quality samples* is significantly faster and more reliable than the Vanilla GAN.\n",
    "*   **SNGAN**: This model also demonstrated stable training, similar to WGAN. Its loss curves were smooth and did not diverge. However, its final image quality (as measured by FID) was not as good as WGAN's in this specific experiment, suggesting that while the training was stable, it did not converge to an optimal solution within 50 epochs with the given hyperparameters.\n",
    "\n",
    "### Mode Collapse\n",
    "\n",
    "Mode collapse is a classic failure mode where the generator produces only a limited variety of samples. \n",
    "*   The **Vanilla GAN** is highly susceptible to this, although our run (with an IS of 2.10) managed to avoid a catastrophic collapse and produced a diverse set of digits.\n",
    "*   Both **WGAN** and **SNGAN** are specifically designed to mitigate mode collapse by providing more stable gradients that encourage the generator to explore the entire data distribution. The diversity seen in their output grids supports their effectiveness in this regard.\n",
    "\n",
    "### Analysis of Evaluation Metrics (IS and FID)\n",
    "\n",
    "The quantitative scores tell a compelling story:\n",
    "\n",
    "*   **FID as the Key Metric**: The Fréchet Inception Distance proved to be the most decisive metric for judging realism. The **WGAN's FID of 91.09** represents a massive leap in quality over the **Vanilla GAN's 143.59**. This numerically validates that WGAN's generated distribution is much closer to the real one. The **SNGAN's FID of 108.99**, while a major improvement over the Vanilla GAN, did not reach the level of the WGAN.\n",
    "\n",
    "*   **The SNGAN Result - A Lesson in Hyperparameters**: The fact that SNGAN did not outperform WGAN is an important lesson. SNGAN is often considered state-of-the-art for GAN stabilization, but its performance is not automatic. This result strongly suggests that the chosen learning rate and Adam optimizer parameters were a better fit for WGAN's training dynamics than for SNGAN's. The SNGAN would likely surpass the WGAN with further tuning (e.g., adjusting the learning rate or training for more epochs).\n",
    "\n",
    "### Final Conclusion\n",
    "\n",
    "In this controlled experiment, the **WGAN with weight clipping delivered the best overall performance**, achieving the lowest FID score and demonstrating a great balance of training stability and high-quality results with minimal tuning. \n",
    "\n",
    "The experiment successfully demonstrates that moving beyond the original BCE loss to more advanced frameworks like Wasserstein distance or Spectral Normalization provides a clear, measurable, and significant improvement to the stability and performance of Generative Adversarial Networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
