{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jawahars/ai-gan/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm83MFdyVHMX"
      },
      "source": [
        "## **Project: A Trilogy of GANs on MNIST**\n",
        "\n",
        "This notebook implements and compares three foundational types of Generative Adversarial Networks.\n",
        "\n",
        "*   **Part 1: Vanilla GAN**: The original GAN architecture using Binary Cross-Entropy loss.\n",
        "*   **Part 2: Wasserstein GAN (WGAN)**: An improved architecture using Wasserstein loss and weight clipping to enhance training stability.\n",
        "*   **Part 3: Spectral Normalization GAN (SNGAN)**: A modern approach using Spectral Normalization and Hinge Loss for even more stable and high-quality training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWVRoNRiVHMe"
      },
      "source": [
        "### **Common Setup: Imports and Reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mFQyMywoVHMe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lXU3nxekVHMi"
      },
      "outputs": [],
      "source": [
        "# --- Set a Global Random Seed for Reproducibility ---\n",
        "# This ensures that weight initializations, data shuffling, and noise vectors are the same for each run,\n",
        "# allowing for a fair comparison between variants.\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # For multi-GPU setups\n",
        "    # The following two lines are for full reproducibility on GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vYyXpQbAVHMj"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "image_size = 28 * 28\n",
        "batch_size = 128\n",
        "num_epochs = 50\n",
        "\n",
        "# Image processing and dataset loading\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skLLb4liVHMl"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOj7MZFDVHMm"
      },
      "source": [
        "## **Part 1: Vanilla GAN with BCE Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oZutEwt4VHMo"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(image_size, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid() # Outputs a probability\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, image_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M8smhHKaVHMo",
        "outputId": "bac66cbe-0854-49d0-f981-e88d0d2444df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Vanilla GAN Training...\n",
            "Epoch [1/50], D Loss: 0.5724, G Loss: 3.5371\n",
            "Epoch [2/50], D Loss: 0.5303, G Loss: 3.3323\n",
            "Epoch [3/50], D Loss: 0.8558, G Loss: 2.3385\n",
            "Epoch [4/50], D Loss: 0.8458, G Loss: 2.7774\n",
            "Epoch [5/50], D Loss: 1.1185, G Loss: 2.0056\n",
            "Epoch [6/50], D Loss: 1.1933, G Loss: 2.0702\n",
            "Epoch [7/50], D Loss: 1.2112, G Loss: 2.1464\n",
            "Epoch [8/50], D Loss: 1.0813, G Loss: 1.6654\n",
            "Epoch [9/50], D Loss: 0.9060, G Loss: 1.7896\n",
            "Epoch [10/50], D Loss: 0.6319, G Loss: 2.3653\n",
            "Epoch [11/50], D Loss: 0.6195, G Loss: 2.3977\n",
            "Epoch [12/50], D Loss: 0.6485, G Loss: 2.5455\n",
            "Epoch [13/50], D Loss: 0.5769, G Loss: 3.0423\n",
            "Epoch [14/50], D Loss: 0.5216, G Loss: 3.0470\n",
            "Epoch [15/50], D Loss: 0.5751, G Loss: 2.8559\n",
            "Epoch [16/50], D Loss: 0.5288, G Loss: 2.8231\n",
            "Epoch [17/50], D Loss: 0.6179, G Loss: 2.5799\n",
            "Epoch [18/50], D Loss: 0.6575, G Loss: 2.7438\n",
            "Epoch [19/50], D Loss: 0.5196, G Loss: 3.0139\n",
            "Epoch [20/50], D Loss: 0.5461, G Loss: 3.1352\n",
            "Epoch [21/50], D Loss: 0.5466, G Loss: 3.0050\n",
            "Epoch [22/50], D Loss: 0.4782, G Loss: 3.2592\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3911234696.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mg_optimizer_vanilla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mg_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_vanilla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2175230495.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "learning_rate_vanilla = 0.0002\n",
        "\n",
        "discriminator_vanilla = Discriminator().to(device)\n",
        "generator_vanilla = Generator().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer_vanilla = optim.Adam(discriminator_vanilla.parameters(), lr=learning_rate_vanilla)\n",
        "g_optimizer_vanilla = optim.Adam(generator_vanilla.parameters(), lr=learning_rate_vanilla)\n",
        "d_losses_vanilla, g_losses_vanilla = [], []\n",
        "\n",
        "os.makedirs('vanilla_gan_samples', exist_ok=True)\n",
        "\n",
        "print(\"Starting Vanilla GAN Training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_d_loss, epoch_g_loss = 0.0, 0.0\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "        real_labels = torch.ones(images.size(0), 1).to(device)\n",
        "        fake_labels = torch.zeros(images.size(0), 1).to(device)\n",
        "        images = images.reshape(-1, image_size).to(device)\n",
        "\n",
        "        d_optimizer_vanilla.zero_grad()\n",
        "        d_real_outputs = discriminator_vanilla(images)\n",
        "        d_loss_real = criterion(d_real_outputs, real_labels)\n",
        "        z = torch.randn(images.size(0), latent_dim).to(device)\n",
        "        fake_images = generator_vanilla(z)\n",
        "        d_fake_outputs = discriminator_vanilla(fake_images.detach())\n",
        "        d_loss_fake = criterion(d_fake_outputs, fake_labels)\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        d_optimizer_vanilla.step()\n",
        "\n",
        "        g_optimizer_vanilla.zero_grad()\n",
        "        g_outputs = discriminator_vanilla(fake_images)\n",
        "        g_loss = criterion(g_outputs, real_labels)\n",
        "        g_loss.backward()\n",
        "        g_optimizer_vanilla.step()\n",
        "\n",
        "        epoch_d_loss += d_loss.item()\n",
        "        epoch_g_loss += g_loss.item()\n",
        "\n",
        "    avg_d_loss = epoch_d_loss / len(train_loader)\n",
        "    avg_g_loss = epoch_g_loss / len(train_loader)\n",
        "    d_losses_vanilla.append(avg_d_loss)\n",
        "    g_losses_vanilla.append(avg_g_loss)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], D Loss: {avg_d_loss:.4f}, G Loss: {avg_g_loss:.4f}')\n",
        "\n",
        "print(\"Vanilla GAN Training finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La5fVphjVHMr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e1rLK-yVHMs"
      },
      "source": [
        "## **Part 2: Wasserstein GAN (WGAN) with Weight Clipping**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUiJabAAVHMs"
      },
      "outputs": [],
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Critic, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(image_size, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1) # No Sigmoid for WGAN critic\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JJSbFP1VHMt"
      },
      "outputs": [],
      "source": [
        "learning_rate_wgan = 0.00005\n",
        "critic_iterations = 5\n",
        "clip_value = 0.01\n",
        "\n",
        "critic_wgan = Critic().to(device)\n",
        "generator_wgan = Generator().to(device)\n",
        "d_optimizer_wgan = optim.RMSprop(critic_wgan.parameters(), lr=learning_rate_wgan)\n",
        "g_optimizer_wgan = optim.RMSprop(generator_wgan.parameters(), lr=learning_rate_wgan)\n",
        "d_losses_wgan, g_losses_wgan = [], []\n",
        "\n",
        "os.makedirs('wgan_samples', exist_ok=True)\n",
        "\n",
        "print(\"Starting WGAN Training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_d_loss, epoch_g_loss = 0.0, 0.0\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "        images = images.reshape(-1, image_size).to(device)\n",
        "\n",
        "        for _ in range(critic_iterations):\n",
        "            d_optimizer_wgan.zero_grad()\n",
        "            z = torch.randn(images.size(0), latent_dim).to(device)\n",
        "            fake_images = generator_wgan(z).detach()\n",
        "            real_output = critic_wgan(images)\n",
        "            fake_output = critic_wgan(fake_images)\n",
        "            d_loss = -(torch.mean(real_output) - torch.mean(fake_output))\n",
        "            d_loss.backward()\n",
        "            d_optimizer_wgan.step()\n",
        "            for p in critic_wgan.parameters():\n",
        "                p.data.clamp_(-clip_value, clip_value)\n",
        "\n",
        "        epoch_d_loss += d_loss.item()\n",
        "\n",
        "        g_optimizer_wgan.zero_grad()\n",
        "        z = torch.randn(images.size(0), latent_dim).to(device)\n",
        "        fake_images_for_g = generator_wgan(z)\n",
        "        g_loss = -torch.mean(critic_wgan(fake_images_for_g))\n",
        "        g_loss.backward()\n",
        "        g_optimizer_wgan.step()\n",
        "\n",
        "        epoch_g_loss += g_loss.item()\n",
        "\n",
        "    avg_d_loss = epoch_d_loss / len(train_loader)\n",
        "    avg_g_loss = epoch_g_loss / len(train_loader)\n",
        "    d_losses_wgan.append(avg_d_loss)\n",
        "    g_losses_wgan.append(avg_g_loss)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Critic Loss: {avg_d_loss:.4f}, Generator Loss: {avg_g_loss:.4f}')\n",
        "\n",
        "print(\"WGAN Training finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezHOWrg5VHMt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXPK3_raVHMt"
      },
      "source": [
        "## **Part 3: Spectral Normalization GAN (SNGAN) with Hinge Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MthH2ctsVHMu"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils import spectral_norm\n",
        "\n",
        "class SNGAN_Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SNGAN_Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            spectral_norm(nn.Linear(image_size, 512)),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            spectral_norm(nn.Linear(512, 256)),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            spectral_norm(nn.Linear(256, 1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5F81JQ9VHMu"
      },
      "outputs": [],
      "source": [
        "learning_rate_sngan = 0.0002\n",
        "\n",
        "discriminator_sngan = SNGAN_Discriminator().to(device)\n",
        "generator_sngan = Generator().to(device)\n",
        "d_optimizer_sngan = optim.Adam(discriminator_sngan.parameters(), lr=learning_rate_sngan, betas=(0.5, 0.999))\n",
        "g_optimizer_sngan = optim.Adam(generator_sngan.parameters(), lr=learning_rate_sngan, betas=(0.5, 0.999))\n",
        "d_losses_sngan, g_losses_sngan = [], []\n",
        "\n",
        "os.makedirs('sngan_samples', exist_ok=True)\n",
        "\n",
        "print(\"Starting SNGAN Training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_d_loss, epoch_g_loss = 0.0, 0.0\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "        images = images.reshape(-1, image_size).to(device)\n",
        "\n",
        "        d_optimizer_sngan.zero_grad()\n",
        "        real_output = discriminator_sngan(images)\n",
        "        d_loss_real = torch.mean(nn.ReLU()(1.0 - real_output))\n",
        "        z = torch.randn(images.size(0), latent_dim).to(device)\n",
        "        fake_images = generator_sngan(z).detach()\n",
        "        fake_output = discriminator_sngan(fake_images)\n",
        "        d_loss_fake = torch.mean(nn.ReLU()(1.0 + fake_output))\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        d_optimizer_sngan.step()\n",
        "        epoch_d_loss += d_loss.item()\n",
        "\n",
        "        g_optimizer_sngan.zero_grad()\n",
        "        z = torch.randn(images.size(0), latent_dim).to(device)\n",
        "        fake_images_for_g = generator_sngan(z)\n",
        "        g_output = discriminator_sngan(fake_images_for_g)\n",
        "        g_loss = -torch.mean(g_output)\n",
        "        g_loss.backward()\n",
        "        g_optimizer_sngan.step()\n",
        "        epoch_g_loss += g_loss.item()\n",
        "\n",
        "    avg_d_loss = epoch_d_loss / len(train_loader)\n",
        "    avg_g_loss = epoch_g_loss / len(train_loader)\n",
        "    d_losses_sngan.append(avg_d_loss)\n",
        "    g_losses_sngan.append(avg_g_loss)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Discriminator Loss: {avg_d_loss:.4f}, Generator Loss: {avg_g_loss:.4f}')\n",
        "\n",
        "print(\"SNGAN Training finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0OmIv2dVHMv"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9_TCFPvVHMv"
      },
      "source": [
        "## **Part 4: Evaluation and Comparison**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fe_3OG4VHMw"
      },
      "source": [
        "#### **Loss Curve Plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yheG79sVHMw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Vanilla GAN Loss\")\n",
        "plt.plot(d_losses_vanilla, label=\"D Loss\")\n",
        "plt.plot(g_losses_vanilla, label=\"G Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"WGAN Loss\")\n",
        "plt.plot(d_losses_wgan, label=\"Critic Loss\")\n",
        "plt.plot(g_losses_wgan, label=\"G Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"SNGAN Loss\")\n",
        "plt.plot(d_losses_sngan, label=\"D Loss\")\n",
        "plt.plot(g_losses_sngan, label=\"G Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('all_loss_curves.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbL6Ra_IVHM1"
      },
      "source": [
        "#### **Final Generated Samples (Fair Comparison)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFQ1fcH8VHM2"
      },
      "outputs": [],
      "source": [
        "# --- Create ONE fixed latent vector for the final comparison ---\n",
        "# This ensures we are comparing what each generator produces from the exact same input noise.\n",
        "fixed_z = torch.randn(64, latent_dim).to(device)\n",
        "\n",
        "def show_final_samples(generator, title, filename, z_vector):\n",
        "    \"\"\"Generates and displays samples from a generator using a fixed noise vector.\"\"\"\n",
        "    generator.eval() # Set generator to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        # Use the fixed z_vector passed as an argument\n",
        "        final_images = generator(z_vector).view(-1, 1, 28, 28)\n",
        "        save_image(final_images, filename, normalize=True)\n",
        "\n",
        "        grid = torchvision.utils.make_grid(final_images, nrow=8, normalize=True)\n",
        "        plt.figure(figsize=(8,8))\n",
        "        plt.imshow(grid.permute(1, 2, 0).cpu())\n",
        "        plt.title(title)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# --- Generate and display samples using the SAME fixed_z for all models ---\n",
        "print(\"Displaying final samples. Each model received the exact same input noise.\")\n",
        "\n",
        "show_final_samples(generator_vanilla, 'Final Vanilla GAN Samples', 'final_vanilla_gan_samples.png', fixed_z)\n",
        "show_final_samples(generator_wgan, 'Final WGAN Samples', 'final_wgan_samples.png', fixed_z)\n",
        "show_final_samples(generator_sngan, 'Final SNGAN Samples', 'final_sngan_samples.png', fixed_z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEkNDJLwVHM2"
      },
      "source": [
        "#### **IS and FID Score Calculation setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ1aSpgDVHM2"
      },
      "outputs": [],
      "source": [
        "def generate_for_evaluation(generator, eval_dir, num_images=10000):\n",
        "    os.makedirs(eval_dir, exist_ok=True)\n",
        "    eval_batch_size = 100\n",
        "    print(f\"Generating {num_images} images into '{eval_dir}'...\")\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, num_images, eval_batch_size):\n",
        "            z = torch.randn(eval_batch_size, latent_dim).to(device)\n",
        "            generated_images = generator(z).view(-1, 1, 28, 28)\n",
        "            for j in range(generated_images.size(0)):\n",
        "                save_image(generated_images[j, :, :, :], os.path.join(eval_dir, f'img_{i+j}.png'), normalize=True)\n",
        "    print(f\"Finished generating images for {eval_dir}.\")\n",
        "\n",
        "generate_for_evaluation(generator_vanilla, 'vanilla_eval_images')\n",
        "generate_for_evaluation(generator_wgan, 'wgan_eval_images')\n",
        "generate_for_evaluation(generator_sngan, 'sngan_eval_images')\n",
        "\n",
        "real_images_dir = 'real_mnist_images'\n",
        "if not os.path.exists(real_images_dir):\n",
        "    os.makedirs(real_images_dir, exist_ok=True)\n",
        "    print(f\"Saving real MNIST images to '{real_images_dir}'...\")\n",
        "    real_train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
        "    img_num = 0\n",
        "    for i, (images, _) in enumerate(real_train_loader):\n",
        "        for j in range(images.size(0)):\n",
        "            save_image(images[j, :, :, :], os.path.join(real_images_dir, f'real_img_{img_num}.png'), normalize=True)\n",
        "            img_num += 1\n",
        "    print(\"Finished saving real images.\")\n",
        "else:\n",
        "    print(f\"Real images directory '{real_images_dir}' already exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfNVP64uVHM3"
      },
      "source": [
        "#### **Run Evaluation Commands**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RRtDIspVHM3"
      },
      "outputs": [],
      "source": [
        "!pip install torch-fidelity -q\n",
        "\n",
        "print(\"--- Calculating metrics for Vanilla GAN ---\")\n",
        "!python -m torch_fidelity.fidelity --gpu 0 --fid --isc --input1 /content/vanilla_eval_images --input2 /content/real_mnist_images\n",
        "\n",
        "print(\"\\n--- Calculating metrics for WGAN ---\")\n",
        "!python -m torch_fidelity.fidelity --gpu 0 --fid --isc --input1 /content/wgan_eval_images --input2 /content/real_mnist_images\n",
        "\n",
        "print(\"\\n--- Calculating metrics for SNGAN ---\")\n",
        "!python -m torch_fidelity.fidelity --gpu 0 --fid --isc --input1 /content/sngan_eval_images --input2 /content/real_mnist_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q32-4lQlVHM3"
      },
      "source": [
        "## **Final Comparison**\n",
        "After running the notebook and calculating the metrics, fill in the table below with the final scores to compare the performance of the three models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ1i-q5sVHM3"
      },
      "source": [
        "| Metric | Vanilla GAN (BCE Loss) | WGAN (Wasserstein Loss) | SNGAN (Hinge Loss) | Analysis |\n",
        "| :--- | :--- | :--- | :--- | :--- |\n",
        "| **Stabilization Method** | None (uses Sigmoid) | Weight Clipping | Spectral Normalization | SNGAN provides the most principled and effective way to enforce the Lipschitz constraint, avoiding issues like exploding/vanishing gradients (WGAN clipping) or mode collapse (Vanilla). |\n",
        "| **Training Stability** | Loss is often volatile and not a good indicator of sample quality. | Loss is more meaningful (approximates Earth Mover's distance) and stable. | Stable training with meaningful loss curves. Typically converges faster and more reliably than WGAN. |\n",
        "| **Visual Quality** | Often suffers from noise and artifacts. | Generally cleaner images than Vanilla GAN but can sometimes produce lower-quality samples if clipping is not tuned well. | Typically produces the sharpest and cleanest images with the fewest artifacts among the three. |\n",
        "| **Inception Score (IS)** | *Fill in from output* | *Fill in from output* | *Fill in from output* | SNGAN is expected to have the highest IS, followed by WGAN, then Vanilla GAN. |\n",
        "| **Fr√©chet Distance (FID)** | *Fill in from output* | *Fill in from output* | *Fill in from output* | SNGAN is expected to have the lowest FID, followed by WGAN, then Vanilla GAN. |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}