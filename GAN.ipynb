{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project: Vanilla GAN and WGAN on MNIST**\n",
    "\n",
    "This notebook implements and compares two types of Generative Adversarial Networks.\n",
    "\n",
    "*   **Part 1: Vanilla GAN**: The foundational GAN architecture using Binary Cross-Entropy loss.\n",
    "*   **Part 2: Wasserstein GAN (WGAN)**: An improved architecture using Wasserstein loss and weight clipping to enhance training stability and image quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Common Setup: Imports and Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "image_size = 28 * 28\n",
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "\n",
    "# Image processing and dataset loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1: Vanilla GAN with BCE Loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vanilla GAN Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid() # Outputs a probability\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, image_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vanilla GAN Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_vanilla = 0.0002\n",
    "\n",
    "# Initialize models\n",
    "discriminator_vanilla = Discriminator().to(device)\n",
    "generator_vanilla = Generator().to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer_vanilla = optim.Adam(discriminator_vanilla.parameters(), lr=learning_rate_vanilla)\n",
    "g_optimizer_vanilla = optim.Adam(generator_vanilla.parameters(), lr=learning_rate_vanilla)\n",
    "\n",
    "# Lists to store loss history for plotting\n",
    "d_losses_vanilla = []\n",
    "g_losses_vanilla = []\n",
    "\n",
    "os.makedirs('vanilla_gan_samples', exist_ok=True)\n",
    "\n",
    "print(\"Starting Vanilla GAN Training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_d_loss = 0.0\n",
    "    epoch_g_loss = 0.0\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        real_labels = torch.ones(images.size(0), 1).to(device)\n",
    "        fake_labels = torch.zeros(images.size(0), 1).to(device)\n",
    "        images = images.reshape(-1, image_size).to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        d_optimizer_vanilla.zero_grad()\n",
    "        d_real_outputs = discriminator_vanilla(images)\n",
    "        d_loss_real = criterion(d_real_outputs, real_labels)\n",
    "        z = torch.randn(images.size(0), latent_dim).to(device)\n",
    "        fake_images = generator_vanilla(z)\n",
    "        d_fake_outputs = discriminator_vanilla(fake_images.detach())\n",
    "        d_loss_fake = criterion(d_fake_outputs, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        d_optimizer_vanilla.step()\n",
    "\n",
    "        # Train Generator\n",
    "        g_optimizer_vanilla.zero_grad()\n",
    "        g_outputs = discriminator_vanilla(fake_images)\n",
    "        g_loss = criterion(g_outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        g_optimizer_vanilla.step()\n",
    "        \n",
    "        epoch_d_loss += d_loss.item()\n",
    "        epoch_g_loss += g_loss.item()\n",
    "\n",
    "    # End of Epoch Logging\n",
    "    avg_d_loss = epoch_d_loss / len(train_loader)\n",
    "    avg_g_loss = epoch_g_loss / len(train_loader)\n",
    "    d_losses_vanilla.append(avg_d_loss)\n",
    "    g_losses_vanilla.append(avg_g_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], D Loss: {avg_d_loss:.4f}, G Loss: {avg_g_loss:.4f}')\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        save_image(fake_images.view(-1, 1, 28, 28), f'vanilla_gan_samples/samples_epoch_{epoch+1}.png', normalize=True)\n",
    "\n",
    "print(\"Vanilla GAN Training finished.\")\n",
    "torch.save(generator_vanilla.state_dict(), 'generator_vanilla_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2: Wasserstein GAN (WGAN) with Weight Clipping**\n",
    "\n",
    "This section implements the WGAN. Key changes include:\n",
    "1.  **Critic Model**: The Discriminator (now called a Critic) does not have a final Sigmoid layer.\n",
    "2.  **Wasserstein Loss**: A new loss function that measures the Earth Mover's distance.\n",
    "3.  **Weight Clipping**: The critic's weights are clamped to a small range after each update to enforce the Lipschitz constraint.\n",
    "4.  **RMSProp Optimizer**: As suggested in the original WGAN paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **WGAN Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Critic model for WGAN is a discriminator without the final sigmoid layer\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1) # No Sigmoid\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# The Generator is the same as in the Vanilla GAN\n",
    "# We will create new instances for the WGAN training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **WGAN Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGAN specific hyperparameters\n",
    "learning_rate_wgan = 0.00005\n",
    "critic_iterations = 5 # Number of critic updates per generator update\n",
    "clip_value = 0.01 # Weight clipping value\n",
    "\n",
    "# Initialize models\n",
    "critic_wgan = Critic().to(device)\n",
    "generator_wgan = Generator().to(device)\n",
    "\n",
    "# Optimizers - RMSprop is recommended for WGAN\n",
    "d_optimizer_wgan = optim.RMSprop(critic_wgan.parameters(), lr=learning_rate_wgan)\n",
    "g_optimizer_wgan = optim.RMSprop(generator_wgan.parameters(), lr=learning_rate_wgan)\n",
    "\n",
    "# Lists to store loss history\n",
    "d_losses_wgan = []\n",
    "g_losses_wgan = []\n",
    "\n",
    "os.makedirs('wgan_samples', exist_ok=True)\n",
    "\n",
    "print(\"Starting WGAN Training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_d_loss = 0.0\n",
    "    epoch_g_loss = 0.0\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, image_size).to(device)\n",
    "\n",
    "        # --- Train Critic --- \n",
    "        for _ in range(critic_iterations):\n",
    "            d_optimizer_wgan.zero_grad()\n",
    "            \n",
    "            # Sample noise and generate fake images\n",
    "            z = torch.randn(images.size(0), latent_dim).to(device)\n",
    "            fake_images = generator_wgan(z).detach() # Detach to avoid backprop through generator\n",
    "            \n",
    "            # Calculate critic scores\n",
    "            real_output = critic_wgan(images)\n",
    "            fake_output = critic_wgan(fake_images)\n",
    "            \n",
    "            # Wasserstein loss\n",
    "            d_loss = -(torch.mean(real_output) - torch.mean(fake_output))\n",
    "            d_loss.backward()\n",
    "            d_optimizer_wgan.step()\n",
    "\n",
    "            # Clip weights of critic\n",
    "            for p in critic_wgan.parameters():\n",
    "                p.data.clamp_(-clip_value, clip_value)\n",
    "        \n",
    "        epoch_d_loss += d_loss.item()\n",
    "\n",
    "        # --- Train Generator ---\n",
    "        g_optimizer_wgan.zero_grad()\n",
    "        \n",
    "        # Generate new fake images\n",
    "        z = torch.randn(images.size(0), latent_dim).to(device)\n",
    "        fake_images_for_g = generator_wgan(z)\n",
    "        \n",
    "        # Calculate loss for generator\n",
    "        g_loss = -torch.mean(critic_wgan(fake_images_for_g))\n",
    "        g_loss.backward()\n",
    "        g_optimizer_wgan.step()\n",
    "\n",
    "        epoch_g_loss += g_loss.item()\n",
    "\n",
    "    # End of Epoch Logging\n",
    "    # Note: For WGAN, the critic loss is divided by critic_iterations for a fair comparison per batch\n",
    "    avg_d_loss = epoch_d_loss / len(train_loader)\n",
    "    avg_g_loss = epoch_g_loss / len(train_loader)\n",
    "    d_losses_wgan.append(avg_d_loss)\n",
    "    g_losses_wgan.append(avg_g_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Critic Loss: {avg_d_loss:.4f}, Generator Loss: {avg_g_loss:.4f}')\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        save_image(fake_images_for_g.view(-1, 1, 28, 28), f'wgan_samples/samples_epoch_{epoch+1}.png', normalize=True)\n",
    "\n",
    "print(\"WGAN Training finished.\")\n",
    "torch.save(generator_wgan.state_dict(), 'generator_wgan_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3: Evaluation and Comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loss Curve Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Vanilla GAN Losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Vanilla GAN Loss During Training\")\n",
    "plt.plot(d_losses_vanilla, label=\"Discriminator Loss\")\n",
    "plt.plot(g_losses_vanilla, label=\"Generator Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('vanilla_gan_loss_curves.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot WGAN Losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"WGAN Loss During Training\")\n",
    "plt.plot(d_losses_wgan, label=\"Critic Loss\")\n",
    "plt.plot(g_losses_wgan, label=\"Generator Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('wgan_loss_curves.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Final Generated Samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final samples from Vanilla GAN\n",
    "with torch.no_grad():\n",
    "    z_final = torch.randn(64, latent_dim).to(device)\n",
    "    final_images = generator_vanilla(z_final).view(-1, 1, 28, 28)\n",
    "    save_image(final_images, 'final_vanilla_gan_samples.png', normalize=True)\n",
    "    grid = torchvision.utils.make_grid(final_images, nrow=8, normalize=True)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(grid.permute(1, 2, 0).cpu())\n",
    "    plt.title('Final Vanilla GAN Samples')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Generate final samples from WGAN\n",
    "with torch.no_grad():\n",
    "    z_final = torch.randn(64, latent_dim).to(device)\n",
    "    final_images = generator_wgan(z_final).view(-1, 1, 28, 28)\n",
    "    save_image(final_images, 'final_wgan_samples.png', normalize=True)\n",
    "    grid = torchvision.utils.make_grid(final_images, nrow=8, normalize=True)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(grid.permute(1, 2, 0).cpu())\n",
    "    plt.title('Final WGAN Samples')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **IS and FID Score Calculation**\n",
    "To calculate these metrics, we first generate a large number of samples from each model and save them to a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install evaluation library\n",
    "!pip install torch-fidelity\n",
    "\n",
    "# --- Function to generate and save images for evaluation ---\n",
    "def generate_for_evaluation(generator, eval_dir, num_images=10000):\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "    eval_batch_size = 100\n",
    "    print(f\"Generating {num_images} images into '{eval_dir}'...\")\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_images, eval_batch_size):\n",
    "            z = torch.randn(eval_batch_size, latent_dim).to(device)\n",
    "            generated_images = generator(z).view(-1, 1, 28, 28)\n",
    "            for j in range(generated_images.size(0)):\n",
    "                save_image(generated_images[j, :, :, :], os.path.join(eval_dir, f'img_{i+j}.png'), normalize=True)\n",
    "    print(\"Finished generating images.\")\n",
    "\n",
    "# Generate images for both models\n",
    "generate_for_evaluation(generator_vanilla, 'vanilla_eval_images')\n",
    "generate_for_evaluation(generator_wgan, 'wgan_eval_images')\n",
    "\n",
    "# --- Create a directory of Real MNIST Images for Comparison ---\n",
    "real_images_dir = 'real_mnist_images'\n",
    "if not os.path.exists(real_images_dir):\n",
    "    os.makedirs(real_images_dir, exist_ok=True)\n",
    "    print(f\"Saving real MNIST images to '{real_images_dir}'...\")\n",
    "    real_train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    img_num = 0\n",
    "    for i, (images, _) in enumerate(real_train_loader):\n",
    "        for j in range(images.size(0)):\n",
    "            save_image(images[j, :, :, :], os.path.join(real_images_dir, f'real_img_{img_num}.png'), normalize=True)\n",
    "            img_num += 1\n",
    "    print(\"Finished saving real images.\")\n",
    "else:\n",
    "    print(f\"Real images directory '{real_images_dir}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run Evaluation Commands**\n",
    "Run the following commands to get the IS and FID scores for each model. The results can then be compiled into the final summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Calculating metrics for Vanilla GAN ---\")\n",
    "!python -m torch_fidelity.fidelity --gpu 0 --fid --isc --input1 /content/vanilla_eval_images --input2 /content/real_mnist_images\n",
    "\n",
    "print(\"\\n--- Calculating metrics for WGAN ---\")\n",
    "!python -m torch_fidelity.fidelity --gpu 0 --fid --isc --input1 /content/wgan_eval_images --input2 /content/real_mnist_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Final Comparison**\n",
    "After running the notebook and calculating the metrics, fill in the table below with the final scores to compare the performance of the two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric | Vanilla GAN (BCE Loss) | WGAN (Wasserstein Loss) | Analysis |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Training Stability** | Loss curves are often volatile and less indicative of image quality. Prone to mode collapse. | Loss curves are more stable and meaningful. The critic's loss correlates better with sample quality. More resistant to mode collapse. |\n",
    "| **Visual Quality** | Generated images often suffer from noise and minor artifacts. | Generated images are typically cleaner, with fewer artifacts and sharper details due to more stable training gradients. |\n",
    "| **Inception Score (IS)** | *~2.21* | *Fill in from output* | The WGAN is expected to have a higher IS, indicating better quality and diversity. |\n",
    "| **Fréchet Inception Distance (FID)** | *~136.97* | *Fill in from output* | The WGAN is expected to have a significantly lower FID, showing its output distribution is closer to the real data. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
